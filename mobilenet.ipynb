{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEz6RPOrt2uZ",
        "outputId": "24ee83df-4436-476c-fbd2-cabc2cfac8a9"
      },
      "source": [
        "pip install mxnet"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HPiFz2nu-pO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXfFYEd_u0LH",
        "outputId": "20e91b3c-a6d2-4184-d6cc-ba648009657e"
      },
      "source": [
        "pip install gluonnlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.6)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595723 sha256=983da3b4bdf6099956c35638ffaf8007917382f255a33d4490fe3ff5275ae58c\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtNVj80hvAIr"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import argparse, time, logging\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "from mxnet import gluon, nd\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data import imagenet\n",
        "from gluoncv.utils import makedirs, TrainingHistory\n",
        "\n",
        "import os\n",
        "from mxnet.context import cpu\n",
        "from mxnet.gluon.block import HybridBlock\n",
        "from mxnet.gluon.contrib.nn import HybridConcurrent\n",
        "import multiprocessing"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8UR1oN8vEyq"
      },
      "source": [
        "pip install gluoncv mxnet-cu110>=1.6.0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Ybh4CCvRtF"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import argparse, time, logging\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "from mxnet import gluon, nd\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data import imagenet\n",
        "from gluoncv.utils import makedirs, TrainingHistory\n",
        "\n",
        "import os\n",
        "from mxnet.context import cpu\n",
        "from mxnet.gluon.block import HybridBlock\n",
        "from mxnet.gluon.contrib.nn import HybridConcurrent\n",
        "import multiprocessing"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrpcCx0ovdEd"
      },
      "source": [
        "# specify model - choose from (mobilenetv2_1.0, mobilenetv2_0.5)\n",
        "model_name = 'mobilenetv2_1.0' \n",
        "\n",
        "# path to training and validation images to use\n",
        "data_dir = '/input_0.pb'\n",
        "\n",
        "# training batch size per device (CPU/GPU)\n",
        "batch_size = 40\n",
        "\n",
        "# number of GPUs to use (automatically detect the number of GPUs)\n",
        "num_gpus = len(mx.test_utils.list_gpus())\n",
        "\n",
        "# number of pre-processing workers (automatically detect the number of workers)\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "# number of training epochs \n",
        "#used as 480 for all of the models , used 1 over here to show demo for 1 epoch\n",
        "num_epochs = 1\n",
        "\n",
        "# learning rate\n",
        "lr = 0.045\n",
        "\n",
        "# momentum value for optimizer\n",
        "momentum = 0.9\n",
        "\n",
        "# weight decay rate\n",
        "wd = 0.00004\n",
        "\n",
        "# decay rate of learning rate\n",
        "lr_decay = 0.98\n",
        "\n",
        "# interval for periodic learning rate decays\n",
        "lr_decay_period = 1\n",
        "# epoches at which learning rate decays\n",
        "lr_decay_epoch = '30,60,90'\n",
        "\n",
        "# mode in which to train the model. options are symbolic, imperative, hybrid\n",
        "mode = 'hybrid'\n",
        "\n",
        "# Number of batches to wait before logging\n",
        "log_interval = 50\n",
        "\n",
        "# frequency of model saving\n",
        "save_frequency = 10\n",
        "\n",
        "# directory of saved models\n",
        "save_dir = 'params'\n",
        "\n",
        "#directory of training logs\n",
        "logging_dir = 'logs'\n",
        "\n",
        "# the path to save the history plot\n",
        "save_plot_dir = '.'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "2rG2zyO0g8ml",
        "outputId": "0e74a953-626b-473e-a86d-3ecde1937c17"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('input_0.pb')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7e4c9a05873b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_0.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must either be a directory or not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kckaIFN_vlOf"
      },
      "source": [
        "##This block contains definition for Mobilenet v2\n",
        "\n",
        "# Helpers\n",
        "class RELU6(nn.HybridBlock):\n",
        "    \"\"\"Relu6 used in MobileNetV2.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(RELU6, self).__init__(**kwargs)\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        return F.clip(x, 0, 6, name=\"relu6\")\n",
        "\n",
        "\n",
        "def _add_conv(out, channels=1, kernel=1, stride=1, pad=0,\n",
        "              num_group=1, active=True, relu6=False):\n",
        "    out.add(nn.Conv2D(channels, kernel, stride, pad, groups=num_group, use_bias=False))\n",
        "    out.add(nn.BatchNorm(scale=True))\n",
        "    if active:\n",
        "        out.add(RELU6() if relu6 else nn.Activation('relu'))\n",
        "\n",
        "\n",
        "def _add_conv_dw(out, dw_channels, channels, stride, relu6=False):\n",
        "    _add_conv(out, channels=dw_channels, kernel=3, stride=stride,\n",
        "              pad=1, num_group=dw_channels, relu6=relu6)\n",
        "    _add_conv(out, channels=channels, relu6=relu6)\n",
        "\n",
        "\n",
        "class LinearBottleneck(nn.HybridBlock):\n",
        "    r\"\"\"LinearBottleneck used in MobileNetV2 model from the\n",
        "    `\"Inverted Residuals and Linear Bottlenecks:\n",
        "      Mobile Networks for Classification, Detection and Segmentation\"\n",
        "    <https://arxiv.org/abs/1801.04381>`_ paper.\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : int\n",
        "        Number of input channels.\n",
        "    channels : int\n",
        "        Number of output channels.\n",
        "    t : int\n",
        "        Layer expansion ratio.\n",
        "    stride : int\n",
        "        stride\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, channels, t, stride, **kwargs):\n",
        "        super(LinearBottleneck, self).__init__(**kwargs)\n",
        "        self.use_shortcut = stride == 1 and in_channels == channels\n",
        "        with self.name_scope():\n",
        "            self.out = nn.HybridSequential()\n",
        "\n",
        "            _add_conv(self.out, in_channels * t, relu6=True)\n",
        "            _add_conv(self.out, in_channels * t, kernel=3, stride=stride,\n",
        "                      pad=1, num_group=in_channels * t, relu6=True)\n",
        "            _add_conv(self.out, channels, active=False, relu6=True)\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        out = self.out(x)\n",
        "        if self.use_shortcut:\n",
        "            out = F.elemwise_add(out, x)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Net\n",
        "class MobileNetV2(nn.HybridBlock):\n",
        "    r\"\"\"MobileNetV2 model from the\n",
        "    `\"Inverted Residuals and Linear Bottlenecks:\n",
        "      Mobile Networks for Classification, Detection and Segmentation\"\n",
        "    <https://arxiv.org/abs/1801.04381>`_ paper.\n",
        "    Parameters\n",
        "    ----------\n",
        "    multiplier : float, default 1.0\n",
        "        The width multiplier for controling the model size. The actual number of channels\n",
        "        is equal to the original channel size multiplied by this multiplier.\n",
        "    classes : int, default 1000\n",
        "        Number of classes for the output layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, multiplier=1.0, classes=1000, **kwargs):\n",
        "        super(MobileNetV2, self).__init__(**kwargs)\n",
        "        with self.name_scope():\n",
        "            self.features = nn.HybridSequential(prefix='features_')\n",
        "            with self.features.name_scope():\n",
        "                _add_conv(self.features, int(32 * multiplier), kernel=3,\n",
        "                          stride=2, pad=1, relu6=True)\n",
        "\n",
        "                in_channels_group = [int(x * multiplier) for x in [32] + [16] + [24] * 2\n",
        "                                     + [32] * 3 + [64] * 4 + [96] * 3 + [160] * 3]\n",
        "                channels_group = [int(x * multiplier) for x in [16] + [24] * 2 + [32] * 3\n",
        "                                  + [64] * 4 + [96] * 3 + [160] * 3 + [320]]\n",
        "                ts = [1] + [6] * 16\n",
        "                strides = [1, 2] * 2 + [1, 1, 2] + [1] * 6 + [2] + [1] * 3\n",
        "\n",
        "                for in_c, c, t, s in zip(in_channels_group, channels_group, ts, strides):\n",
        "                    self.features.add(LinearBottleneck(in_channels=in_c, channels=c,\n",
        "                                                       t=t, stride=s))\n",
        "\n",
        "                last_channels = int(1280 * multiplier) if multiplier > 1.0 else 1280\n",
        "                _add_conv(self.features, last_channels, relu6=True)\n",
        "\n",
        "                self.features.add(nn.GlobalAvgPool2D())\n",
        "\n",
        "            self.output = nn.HybridSequential(prefix='output_')\n",
        "            with self.output.name_scope():\n",
        "                self.output.add(\n",
        "                    nn.Conv2D(classes, 1, use_bias=False, prefix='pred_'),\n",
        "                    nn.Flatten()\n",
        "                )\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        x = self.features(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Constructor\n",
        "def get_mobilenet_v2(multiplier, **kwargs):\n",
        "    r\"\"\"MobileNetV2 model from the\n",
        "    `\"Inverted Residuals and Linear Bottlenecks:\n",
        "      Mobile Networks for Classification, Detection and Segmentation\"\n",
        "    <https://arxiv.org/abs/1801.04381>`_ paper.\n",
        "    Parameters\n",
        "    ----------\n",
        "    multiplier : float\n",
        "        The width multiplier for controling the model size. Only multipliers that are no\n",
        "        less than 0.25 are supported. The actual number of channels is equal to the original\n",
        "        channel size multiplied by this multiplier.\n",
        "    \"\"\"\n",
        "    net = MobileNetV2(multiplier, **kwargs)\n",
        "    return net\n",
        "\n",
        "def mobilenet_v2_1_0(**kwargs):\n",
        "    r\"\"\"MobileNetV2 model from the\n",
        "    `\"Inverted Residuals and Linear Bottlenecks:\n",
        "      Mobile Networks for Classification, Detection and Segmentation\"\n",
        "    <https://arxiv.org/abs/1801.04381>`_ paper.\n",
        "    \"\"\"\n",
        "    return get_mobilenet_v2(1.0, **kwargs)\n",
        "\n",
        "def mobilenet_v2_0_5(**kwargs):\n",
        "    r\"\"\"MobileNetV2 model from the\n",
        "    `\"Inverted Residuals and Linear Bottlenecks:\n",
        "      Mobile Networks for Classification, Detection and Segmentation\"\n",
        "    <https://arxiv.org/abs/1801.04381>`_ paper.\n",
        "    \"\"\"\n",
        "    return get_mobilenet_v2(0.5, **kwargs)\n",
        "models = {  \n",
        "            'mobilenetv2_1.0': mobilenet_v2_1_0,\n",
        "            'mobilenetv2_0.5': mobilenet_v2_0_5\n",
        "         }"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTQLfGSqvzBS"
      },
      "source": [
        "# Specify logging fucntion\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Specify classes (1000 for ImageNet)\n",
        "classes = 1000\n",
        "# Extrapolate batches to all devices\n",
        "batch_size *= max(1, num_gpus)\n",
        "# Define context\n",
        "context = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
        "\n",
        "lr_decay_epoch = [int(i) for i in lr_decay_epoch.split(',')] + [np.inf]\n",
        "\n",
        "kwargs = {'classes': classes}\n",
        "\n",
        "# Define optimizer (nag = Nestrov Accelerated Gradient)\n",
        "optimizer = 'nag'\n",
        "optimizer_params = {'learning_rate': lr, 'wd': wd, 'momentum': momentum}\n",
        "\n",
        "# Retireve gluon model\n",
        "net = models[model_name](**kwargs)\n",
        "\n",
        "# Define accuracy measures - top1 error and top5 error\n",
        "acc_top1 = mx.metric.Accuracy()\n",
        "acc_top5 = mx.metric.TopKAccuracy(5)\n",
        "train_history = TrainingHistory(['training-top1-err', 'training-top5-err',\n",
        "                                 'validation-top1-err', 'validation-top5-err'])\n",
        "makedirs(save_dir)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlLBVbUzv5I2"
      },
      "source": [
        "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "jitter_param = 0.0\n",
        "lighting_param = 0.0\n",
        "\n",
        "# Input pre-processing for train data\n",
        "def preprocess_train_data(normalize, jitter_param, lighting_param):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize(480),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomFlipLeftRight(),\n",
        "        transforms.RandomColorJitter(brightness=jitter_param, contrast=jitter_param,\n",
        "                                     saturation=jitter_param),\n",
        "        transforms.RandomLighting(lighting_param),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "    return transform_train\n",
        "\n",
        "# Input pre-processing for validation data\n",
        "def preprocess_test_data(normalize):\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "    return transform_test"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQpcQf07v8yE"
      },
      "source": [
        "# Test function\n",
        "def test(ctx, val_data):\n",
        "    # Reset accuracy metrics\n",
        "    acc_top1.reset()\n",
        "    acc_top5.reset()\n",
        "    for i, batch in enumerate(val_data):\n",
        "        # Load validation batch\n",
        "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "        # Perform forward pass\n",
        "        outputs = [net(X) for X in data]\n",
        "        # Update accuracy metrics\n",
        "        acc_top1.update(label, outputs)\n",
        "        acc_top5.update(label, outputs)\n",
        "    # Retrieve and return top1 and top5 errors\n",
        "    _, top1 = acc_top1.get()\n",
        "    _, top5 = acc_top5.get()\n",
        "    return (1-top1, 1-top5)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqceoKInwCa5"
      },
      "source": [
        "# Train function\n",
        "def train(epochs, ctx):\n",
        "    if isinstance(ctx, mx.Context):\n",
        "        ctx = [ctx]\n",
        "    # Initialize network - Use method in MSRA paper <https://arxiv.org/abs/1502.01852>\n",
        "    net.initialize(mx.init.MSRAPrelu(), ctx=ctx)\n",
        "    # Prepare train and validation batches\n",
        "    transform_train = preprocess_train_data(normalize, jitter_param, lighting_param)\n",
        "    transform_test = preprocess_test_data(normalize)\n",
        "    train_data = gluon.data.DataLoader(\n",
        "        imagenet.classification.ImageNet(data_dir, train=True).transform_first(transform_train),\n",
        "        batch_size=batch_size, shuffle=True, last_batch='discard', num_workers=num_workers)\n",
        "    val_data = gluon.data.DataLoader(\n",
        "        imagenet.classification.ImageNet(data_dir, train=False).transform_first(transform_test),\n",
        "        batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    # Define trainer\n",
        "    trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)\n",
        "    # Define loss\n",
        "    L = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "    lr_decay_count = 0\n",
        "\n",
        "    best_val_score = 1\n",
        "    # Main training loop - loop over epochs\n",
        "    for epoch in range(epochs):\n",
        "        tic = time.time()\n",
        "        # Reset accuracy metrics\n",
        "        acc_top1.reset()\n",
        "        acc_top5.reset()\n",
        "        btic = time.time()\n",
        "        train_loss = 0\n",
        "        num_batch = len(train_data)\n",
        "        \n",
        "        # Check and perform learning rate decay\n",
        "        if lr_decay_period and epoch and epoch % lr_decay_period == 0:\n",
        "            trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        elif lr_decay_period == 0 and epoch == lr_decay_epoch[lr_decay_count]:\n",
        "            trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "            lr_decay_count += 1\n",
        "        # Loop over batches in an epoch\n",
        "        for i, batch in enumerate(train_data):\n",
        "            # Load train batch\n",
        "            data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "            label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "            label_smooth = label\n",
        "            # Perform forward pass\n",
        "            with ag.record():\n",
        "                outputs = [net(X) for X in data]\n",
        "                loss = [L(yhat, y) for yhat, y in zip(outputs, label_smooth)]\n",
        "            # Perform backward pass\n",
        "            ag.backward(loss)\n",
        "            # PErform updates\n",
        "            trainer.step(batch_size)\n",
        "            # Update accuracy metrics\n",
        "            acc_top1.update(label, outputs)\n",
        "            acc_top5.update(label, outputs)\n",
        "            # Update loss\n",
        "            train_loss += sum([l.sum().asscalar() for l in loss])\n",
        "            # Log training progress (after each `log_interval` batches)\n",
        "            if log_interval and not (i+1)%log_interval:\n",
        "                _, top1 = acc_top1.get()\n",
        "                _, top5 = acc_top5.get()\n",
        "                err_top1, err_top5 = (1-top1, 1-top5)\n",
        "                logging.info('Epoch[%d] Batch [%d]\\tSpeed: %f samples/sec\\ttop1-err=%f\\ttop5-err=%f'%(\n",
        "                             epoch, i, batch_size*log_interval/(time.time()-btic), err_top1, err_top5))\n",
        "                btic = time.time()\n",
        "\n",
        "        # Retrieve training errors and loss\n",
        "        _, top1 = acc_top1.get()\n",
        "        _, top5 = acc_top5.get()\n",
        "        err_top1, err_top5 = (1-top1, 1-top5)\n",
        "        train_loss /= num_batch * batch_size\n",
        "\n",
        "        # Compute validation errors\n",
        "        err_top1_val, err_top5_val = test(ctx, val_data)\n",
        "        # Update training history\n",
        "        train_history.update([err_top1, err_top5, err_top1_val, err_top5_val])\n",
        "        # Update plot\n",
        "        train_history.plot(['training-top1-err', 'validation-top1-err','training-top5-err', 'validation-top5-err'],\n",
        "                           save_path='%s/%s_top_error.png'%(save_plot_dir, model_name))\n",
        "\n",
        "        # Log training progress (after each epoch)\n",
        "        logging.info('[Epoch %d] training: err-top1=%f err-top5=%f loss=%f'%(epoch, err_top1, err_top5, train_loss))\n",
        "        logging.info('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n",
        "        logging.info('[Epoch %d] validation: err-top1=%f err-top5=%f'%(epoch, err_top1_val, err_top5_val))\n",
        "\n",
        "        # Save a snapshot of the best model - use net.export to get MXNet symbols and params\n",
        "        if err_top1_val < best_val_score and epoch > 50:\n",
        "            best_val_score = err_top1_val\n",
        "            net.export('%s/%.4f-imagenet-%s-best'%(save_dir, best_val_score, model_name), epoch)\n",
        "        # Save a snapshot of the model after each 'save_frequency' epochs\n",
        "        if save_frequency and save_dir and (epoch + 1) % save_frequency == 0:\n",
        "            net.export('%s/%.4f-imagenet-%s'%(save_dir, best_val_score, model_name), epoch)\n",
        "    # Save a snapshot of the model at the end of training\n",
        "    if save_frequency and save_dir:\n",
        "        net.export('%s/%.4f-imagenet-%s'%(save_dir, best_val_score, model_name), epochs-1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkwHvhikwED1"
      },
      "source": [
        "def main():\n",
        "    net.hybridize()\n",
        "    train(num_epochs, context)\n",
        "if __name__ == '/content/input_0.pb':\n",
        "    main()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S5bgxvdyiR5",
        "outputId": "feef3b7b-3d62-4d68-9963-69e8fee7297b"
      },
      "source": [
        "pip install onnxruntime-gpu==1.2.0"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime-gpu==1.2.0 in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: onnx>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu==1.2.0) (1.10.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu==1.2.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.3->onnxruntime-gpu==1.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.3->onnxruntime-gpu==1.2.0) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.3->onnxruntime-gpu==1.2.0) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i8VNHw8zAbx",
        "outputId": "a1ea7d5d-d90e-4f12-92c0-14f990993d10"
      },
      "source": [
        "pip install tf2onnx"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.7/dist-packages (1.9.3)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.10.2)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.4.1->tf2onnx) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.4.1->tf2onnx) (3.17.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPiv0-djzHbd"
      },
      "source": [
        "import tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isq4qRndf4-f",
        "outputId": "cbf33fd9-af7f-49e4-a862-6067ade4c3c6"
      },
      "source": [
        "pip install onnx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Ss_slKf-1J"
      },
      "source": [
        "from onnx import mapping, defs\n",
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "from tf2onnx.constants import OPSET_TO_IR_VERSION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9oIIpRagPbi"
      },
      "source": [
        "def to_tf_tensor_spec(onnx_type, name=None, unknown_dim=1):\n",
        "    shp = [unknown_dim if isinstance(n_, str) else n_ for n_ in onnx_type.shape]\n",
        "    return tf.TensorSpec(shp, mapping.TENSOR_TYPE_TO_NP_TYPE[onnx_type.to_onnx_type().tensor_type.elem_type],\n",
        "                         name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxeLzIC9gTrf"
      },
      "source": [
        "def _process_initial_types(initial_types, unknown_dim=1):\n",
        "    if initial_types is None:\n",
        "        return None\n",
        "\n",
        "    input_specs = []\n",
        "    c_ = 0\n",
        "    while c_ < len(initial_types):\n",
        "        name = None\n",
        "        type_idx = c_\n",
        "        if isinstance(initial_types[c_], str):\n",
        "            name = initial_types[c_]\n",
        "            type_idx = c_ + 1\n",
        "        ts_spec = to_tf_tensor_spec(initial_types[type_idx], name, unknown_dim)\n",
        "        input_specs.append(ts_spec)\n",
        "        c_ += 1 if name is None else 2\n",
        "\n",
        "    return input_specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omFd6P3igZd4"
      },
      "source": [
        "def get_maximum_opset_supported():\n",
        "    return min(max(OPSET_TO_IR_VERSION.keys()), defs.onnx_opset_version())\n",
        "\n",
        "def convert_keras(model, name=None, doc_string='', target_opset=None, initial_types=None,\n",
        "                  channel_first_inputs=None, debug_mode=False, custom_op_conversions=None):\n",
        "    \"\"\"\n",
        "    :param model: keras model\n",
        "    :param name: the converted onnx model internal name\n",
        "    :param doc_string: doc string\n",
        "    :param target_opset: the targeted onnx model opset\n",
        "    :param initial_types: the overridden input type for the target ONNX model.\n",
        "    :param channel_first_inputs: A list of channel first input\n",
        "    :param debug_mode: ignored\n",
        "    :param custom_op_conversions: ignored\n",
        "    :return an ONNX ModelProto\n",
        "    \"\"\"\n",
        "    if target_opset is None:\n",
        "        target_opset = get_maximum_opset_supported()\n",
        "    input_signature = _process_initial_types(initial_types, unknown_dim=None)\n",
        "    name = name or model.name\n",
        "\n",
        "    model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=target_opset,\n",
        "                                          inputs_as_nchw=channel_first_inputs)\n",
        "    model.graph.name = name\n",
        "    model.graph.doc_string = doc_string\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}